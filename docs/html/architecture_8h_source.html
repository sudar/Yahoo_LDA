<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Y!LDA: src/architecture.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.3 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
      <li><a href="globals.html"><span>File&nbsp;Members</span></a></li>
    </ul>
  </div>
<h1>src/architecture.h</h1><a href="architecture_8h.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/*****************************************************************************</span>
<a name="l00002"></a>00002 <span class="comment">     The contents of this file are subject to the Mozilla Public License</span>
<a name="l00003"></a>00003 <span class="comment">     Version 1.1 (the &quot;License&quot;); you may not use this file except in</span>
<a name="l00004"></a>00004 <span class="comment">     compliance with the License. You may obtain a copy of the License at</span>
<a name="l00005"></a>00005 <span class="comment">     http://www.mozilla.org/MPL/</span>
<a name="l00006"></a>00006 <span class="comment"></span>
<a name="l00007"></a>00007 <span class="comment">     Software distributed under the License is distributed on an &quot;AS IS&quot;</span>
<a name="l00008"></a>00008 <span class="comment">     basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the</span>
<a name="l00009"></a>00009 <span class="comment">     License for the specific language governing rights and limitations</span>
<a name="l00010"></a>00010 <span class="comment">     under the License.</span>
<a name="l00011"></a>00011 <span class="comment"></span>
<a name="l00012"></a>00012 <span class="comment">     The Original Code is Copyright (C) by Yahoo! Research.</span>
<a name="l00013"></a>00013 <span class="comment"></span>
<a name="l00014"></a>00014 <span class="comment">     The Initial Developer of the Original Code is Shravan Narayanamurthy.</span>
<a name="l00015"></a>00015 <span class="comment"></span>
<a name="l00016"></a>00016 <span class="comment">     All Rights Reserved.</span>
<a name="l00017"></a>00017 <span class="comment">******************************************************************************/</span><span class="comment"></span>
<a name="l00018"></a>00018 <span class="comment">/**</span>
<a name="l00019"></a>00019 <span class="comment"> * \page architecture Y!LDA Architecture</span>
<a name="l00020"></a>00020 <span class="comment"> * \section intro Introduction</span>
<a name="l00021"></a>00021 <span class="comment"> * Please refer the Main Page for an introduction</span>
<a name="l00022"></a>00022 <span class="comment"> *</span>
<a name="l00023"></a>00023 <span class="comment"> * \section goals Goals</span>
<a name="l00024"></a>00024 <span class="comment"> * The approach to do topic modelling is to have a graphical model representing</span>
<a name="l00025"></a>00025 <span class="comment"> * the generative assumptions the user has about the corpus. A graphical model is a</span>
<a name="l00026"></a>00026 <span class="comment"> * probabilistic model representing the joint distribution of the random</span>
<a name="l00027"></a>00027 <span class="comment"> * variables involved with a graph denoting the conditional independence</span>
<a name="l00028"></a>00028 <span class="comment"> * assumptions amongst them. Solving the model is to infer the parameters of</span>
<a name="l00029"></a>00029 <span class="comment"> * the model by processing the actual data. Doing this inference is the</span>
<a name="l00030"></a>00030 <span class="comment"> * hardest part of the approach.</span>
<a name="l00031"></a>00031 <span class="comment"> *</span>
<a name="l00032"></a>00032 <span class="comment"> * \subsection new_models Adding new Models</span>
<a name="l00033"></a>00033 <span class="comment"> * There are a lot of variations on the basic LDA model and with each variation</span>
<a name="l00034"></a>00034 <span class="comment"> * the inferencing logic changes. The parameters, the sufficient statistics that</span>
<a name="l00035"></a>00035 <span class="comment"> * need to be maintained everything will be slightly different. One of the main</span>
<a name="l00036"></a>00036 <span class="comment"> * goals of this framework is to make the job of adding new models simpler.</span>
<a name="l00037"></a>00037 <span class="comment"> *</span>
<a name="l00038"></a>00038 <span class="comment"> * \subsection infrastructure Common Infrastructure</span>
<a name="l00039"></a>00039 <span class="comment"> * One task that is mostly common across multiple models is the infrastructure</span>
<a name="l00040"></a>00040 <span class="comment"> * needed to store documents, load them, create a pipeline that can optimally</span>
<a name="l00041"></a>00041 <span class="comment"> * utilize multi-core parallelism. In the framework we aim to standardize on</span>
<a name="l00042"></a>00042 <span class="comment"> * proven infrastructure that is known to provide efficient implementations so</span>
<a name="l00043"></a>00043 <span class="comment"> * that the model writer just worries about adding only the parts that are</span>
<a name="l00044"></a>00044 <span class="comment"> * relevant for doing the inference</span>
<a name="l00045"></a>00045 <span class="comment"> *</span>
<a name="l00046"></a>00046 <span class="comment"> * \subsection scalability Scalability</span>
<a name="l00047"></a>00047 <span class="comment"> * Another main aspect of this framework is to substantially increase the scale</span>
<a name="l00048"></a>00048 <span class="comment"> * of the state of the art by utilizing parallelism both multi-core and</span>
<a name="l00049"></a>00049 <span class="comment"> * multi-machine.</span>
<a name="l00050"></a>00050 <span class="comment"> *</span>
<a name="l00051"></a>00051 <span class="comment"> * \section components Main components of the System</span>
<a name="l00052"></a>00052 <span class="comment"> * Y!LDA uses the Gibbs sampling approach popularized by</span>
<a name="l00053"></a>00053 <span class="comment"> * &lt;a href=&quot;http://dx.doi.org/10.1073%2Fpnas.0307752101&quot;&gt;Collapsed Gibbs Sampling&lt;/a&gt;.</span>
<a name="l00054"></a>00054 <span class="comment"> * There are four main components in this approach:</span>
<a name="l00055"></a>00055 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00056"></a>00056 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Model:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00057"></a>00057 <span class="comment"> * This encapsulates the parameters of the model and the sufficient</span>
<a name="l00058"></a>00058 <span class="comment"> *              statistics that are necessary for inference</span>
<a name="l00059"></a>00059 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Model_Refiner:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00060"></a>00060 <span class="comment"> * This encapsulates the logic needed for refining the initial</span>
<a name="l00061"></a>00061 <span class="comment"> *              model which involves streaming the documents from disk, sampling</span>
<a name="l00062"></a>00062 <span class="comment"> *              new topic assignments, updating the model, performing diagnostics</span>
<a name="l00063"></a>00063 <span class="comment"> *              and optimization and writing the documents back to disk</span>
<a name="l00064"></a>00064 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Pipeline:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00065"></a>00065 <span class="comment"> * As can be seen above, the refiner does a sequence of operations on</span>
<a name="l00066"></a>00066 <span class="comment"> *              every document of the corpus. Some of them have to run serially but</span>
<a name="l00067"></a>00067 <span class="comment"> *              some others can be run parallely. To enable exploiting multi-core</span>
<a name="l00068"></a>00068 <span class="comment"> *              parallelism, the Pipeline is defined to be composed of a set of</span>
<a name="l00069"></a>00069 <span class="comment"> *              operations called filters which can either be declared to be run</span>
<a name="l00070"></a>00070 <span class="comment"> *              serially or parallely. The Pipeline comes with a scheduler that</span>
<a name="l00071"></a>00071 <span class="comment"> *              schedules the threads available on the machine to run these filters</span>
<a name="l00072"></a>00072 <span class="comment"> *              in an optimal fashion</span>
<a name="l00073"></a>00073 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Execution_Strategy:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00074"></a>00074 <span class="comment"> * This encapsulates the strategy that decides what filters</span>
<a name="l00075"></a>00075 <span class="comment"> *              a pipeline is composed of, how many times the documents are passed</span>
<a name="l00076"></a>00076 <span class="comment"> *              through the pipeline.</span>
<a name="l00077"></a>00077 <span class="comment"> * &lt;/OL&gt;</span>
<a name="l00078"></a>00078 <span class="comment"> * \subsection builder Builder Pattern</span>
<a name="l00079"></a>00079 <span class="comment"> * The Builder pattern fits very well for this approach. We implement a Model_Builder</span>
<a name="l00080"></a>00080 <span class="comment"> * that builds the last three components depending on what model is needed and what</span>
<a name="l00081"></a>00081 <span class="comment"> * mode the model is supposed to operate in.</span>
<a name="l00082"></a>00082 <span class="comment"> *</span>
<a name="l00083"></a>00083 <span class="comment"> * The Model_Builder creates an initial Model and creates the required Model_Refiner by</span>
<a name="l00084"></a>00084 <span class="comment"> * passing the Model(or the necessary components of the Model). It then creates a Pipeline</span>
<a name="l00085"></a>00085 <span class="comment"> * and an Execution_Strategy as per the mode of operation.</span>
<a name="l00086"></a>00086 <span class="comment"> *</span>
<a name="l00087"></a>00087 <span class="comment"> * The Director is pretty straightforward. It directs the given Model_Builder to create</span>
<a name="l00088"></a>00088 <span class="comment"> * the necessary components and executes the defined Execution_Strategy. This refines the</span>
<a name="l00089"></a>00089 <span class="comment"> * initial Model created by the builder into one that reflects parameters tuned to the</span>
<a name="l00090"></a>00090 <span class="comment"> * corpus on which the Model was refined on. Then the Model is stored on disk for testing.</span>
<a name="l00091"></a>00091 <span class="comment"> *</span>
<a name="l00092"></a>00092 <span class="comment"> * \section multi-machine Distributed Set Up</span>
<a name="l00093"></a>00093 <span class="comment"> * To cater to the Scalability goals, as detailed in</span>
<a name="l00094"></a>00094 <span class="comment"> * &lt;a href=&quot;http://portal.acm.org/citation.cfm?id=1920931&quot;&gt;An Architecture for Parallel Topic Models&lt;/a&gt;,</span>
<a name="l00095"></a>00095 <span class="comment"> * the framework implements a</span>
<a name="l00096"></a>00096 <span class="comment"> * Distributed Memory based multi-machine setup that exploits multi-machine parallelism</span>
<a name="l00097"></a>00097 <span class="comment"> * to the fullest. The main idea being that the inferencing happens locally while the</span>
<a name="l00098"></a>00098 <span class="comment"> * state variables are kept up-to-date with a global copy that stored using a Distributed</span>
<a name="l00099"></a>00099 <span class="comment"> * HashTable. To come up with an efficient distributed set up is a difficult thing and</span>
<a name="l00100"></a>00100 <span class="comment"> * we definitely do not want people reinvent the wheel here. So the framework tries to</span>
<a name="l00101"></a>00101 <span class="comment"> * abstract the mechanism of distribution, the implementation of an efficient distributed</span>
<a name="l00102"></a>00102 <span class="comment"> * HashTable and the mechanism needed for Synchrnoization.</span>
<a name="l00103"></a>00103 <span class="comment"> *</span>
<a name="l00104"></a>00104 <span class="comment"> * \subsection distributed_map Distributed_Map</span>
<a name="l00105"></a>00105 <span class="comment"> * The framework implements a Distributed_Map interface using Ice as a very efficient</span>
<a name="l00106"></a>00106 <span class="comment"> * middleware. It essentially provides both a Server and Client implementation.</span>
<a name="l00107"></a>00107 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00108"></a>00108 <span class="comment"> * &lt;LI&gt;</span>
<a name="l00109"></a>00109 <span class="comment"> * &lt;B&gt;DM_Server:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00110"></a>00110 <span class="comment"> * The server essentially hosts a chunk of the distributed hash table and supports the</span>
<a name="l00111"></a>00111 <span class="comment"> * usual map operations. It also supports three special operations:</span>
<a name="l00112"></a>00112 <span class="comment"> * &lt;UL&gt;</span>
<a name="l00113"></a>00113 <span class="comment"> * &lt;LI&gt;Put: Which accumulates the values instead of replacing&lt;/LI&gt;</span>
<a name="l00114"></a>00114 <span class="comment"> * &lt;LI&gt;waitForAll: Which is a barrier implementation using AMD&lt;/LI&gt;</span>
<a name="l00115"></a>00115 <span class="comment"> * &lt;LI&gt;PutNGet: which is an asynchronous call that accumulates</span>
<a name="l00116"></a>00116 <span class="comment"> *              the passed value into the existing one and returns</span>
<a name="l00117"></a>00117 <span class="comment"> *              the final value back to the caller through</span>
<a name="l00118"></a>00118 <span class="comment"> *              a call back mechanism</span>
<a name="l00119"></a>00119 <span class="comment"> * &lt;/LI&gt;</span>
<a name="l00120"></a>00120 <span class="comment"> * &lt;/UL&gt;</span>
<a name="l00121"></a>00121 <span class="comment"> * &lt;/LI&gt;</span>
<a name="l00122"></a>00122 <span class="comment"> * &lt;LI&gt;</span>
<a name="l00123"></a>00123 <span class="comment"> * &lt;B&gt;DM_Client:&lt;/B&gt; &lt;BR/&gt;</span>
<a name="l00124"></a>00124 <span class="comment"> * A client that supports a single hash table view of the distributed system. The client</span>
<a name="l00125"></a>00125 <span class="comment"> * transparently supports a rate limited, sliding-window based Asynchronous Method Invocation</span>
<a name="l00126"></a>00126 <span class="comment"> * for the PutNGet which is a very useful operation to have for effective Synchronization.</span>
<a name="l00127"></a>00127 <span class="comment"> * Refer to the VLDB paper for more information.</span>
<a name="l00128"></a>00128 <span class="comment"> * &lt;/LI&gt;</span>
<a name="l00129"></a>00129 <span class="comment"> * &lt;/OL&gt;</span>
<a name="l00130"></a>00130 <span class="comment"> *</span>
<a name="l00131"></a>00131 <span class="comment"> * For most models, one need not worry about modifying the above. These only need to be</span>
<a name="l00132"></a>00132 <span class="comment"> * used most of the times without bothering much about their implementation.</span>
<a name="l00133"></a>00133 <span class="comment"> *</span>
<a name="l00134"></a>00134 <span class="comment"> * \subsection synchronizer Synchronizer</span>
<a name="l00135"></a>00135 <span class="comment"> * The framework provides a default implementation of the Synchronization strategy detailed</span>
<a name="l00136"></a>00136 <span class="comment"> * in [2]. The Synchronizer is run as a separate background thread apart from the main</span>
<a name="l00137"></a>00137 <span class="comment"> * threads that do the inferencing. The actual task of synchronization is left to the</span>
<a name="l00138"></a>00138 <span class="comment"> * implementation of a Synchronizer_Helper class. The Sychronizer only creates slots for</span>
<a name="l00139"></a>00139 <span class="comment"> * synchronization and asks the helper to synchronize in those slots. It also takes care</span>
<a name="l00140"></a>00140 <span class="comment"> * of running the Synchronization only till the inferencing is done.</span>
<a name="l00141"></a>00141 <span class="comment"> *</span>
<a name="l00142"></a>00142 <span class="comment"> * However, there is a strong assumption that the synchronization proceeds in a linear</span>
<a name="l00143"></a>00143 <span class="comment"> * fashion. That is the structures being synchronized are linear and can be synchronized</span>
<a name="l00144"></a>00144 <span class="comment"> * one after the other. This is implicit in the Synchronizer&#39;s creation of slots.</span>
<a name="l00145"></a>00145 <span class="comment"> *</span>
<a name="l00146"></a>00146 <span class="comment"> * \subsection synchronizer_helper Synchronizer_Helper</span>
<a name="l00147"></a>00147 <span class="comment"> * Every model has to only provide the Synchronizer_Helper implementation which spills</span>
<a name="l00148"></a>00148 <span class="comment"> * the logic for synchronizing the model&#39;s relevant structures, maintains copies of them</span>
<a name="l00149"></a>00149 <span class="comment"> * where needed and provides the callback function for the AMI putNGet.</span>
<a name="l00150"></a>00150 <span class="comment"> *</span>
<a name="l00151"></a>00151 <span class="comment"> * \section default_impl Default Implementations provided</span>
<a name="l00152"></a>00152 <span class="comment"> * The framework provides default implementations for the Pipeline interface and the</span>
<a name="l00153"></a>00153 <span class="comment"> * Execution_Stratgey interface.</span>
<a name="l00154"></a>00154 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00155"></a>00155 <span class="comment"> * &lt;LI&gt;&lt;B&gt;TBB_Pipeline:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00156"></a>00156 <span class="comment"> * This implementation uses Intel&#39;s Threading Building Blocks for</span>
<a name="l00157"></a>00157 <span class="comment"> *                  providing the Pipeline interface.</span>
<a name="l00158"></a>00158 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Training_Execution_Strategy:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00159"></a>00159 <span class="comment"> * The default implementation of Execution_Strategy for</span>
<a name="l00160"></a>00160 <span class="comment"> * LDA training. Assembles the following pipeline for data flow:</span>
<a name="l00161"></a>00161 <span class="comment"> * \image html data_flow.png</span>
<a name="l00162"></a>00162 <span class="comment"> * \image latex data_flow.eps</span>
<a name="l00163"></a>00163 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Synchronized_Training_Execution_Strategy:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00164"></a>00164 <span class="comment"> * The default implementation of</span>
<a name="l00165"></a>00165 <span class="comment"> *                  Execution_Strategy that extends Training_Execution_Strategy and</span>
<a name="l00166"></a>00166 <span class="comment"> *                  adds Synchronization capability</span>
<a name="l00167"></a>00167 <span class="comment"> * &lt;LI&gt;&lt;B&gt;Testing_Execution_Strategy:&lt;/B&gt;&lt;BR/&gt;</span>
<a name="l00168"></a>00168 <span class="comment"> * The default implementation of Execution_Strategy for</span>
<a name="l00169"></a>00169 <span class="comment"> *                  LDA testing.</span>
<a name="l00170"></a>00170 <span class="comment"> *</span>
<a name="l00171"></a>00171 <span class="comment"> * \section unigram Unigram Model</span>
<a name="l00172"></a>00172 <span class="comment"> * The framework also provides the Unigram_Model implementations of the various common</span>
<a name="l00173"></a>00173 <span class="comment"> * interfaces. This is the basic LDA model with the bag of words assumption. Please</span>
<a name="l00174"></a>00174 <span class="comment"> * take a look at how the various interfaces are implemented. The main implementation</span>
<a name="l00175"></a>00175 <span class="comment"> * needed is for Model &amp; Model_Refiner. Additionally, it implements efficient sparse</span>
<a name="l00176"></a>00176 <span class="comment"> * data structures to store the sufficient statistics.</span>
<a name="l00177"></a>00177 <span class="comment"> *</span>
<a name="l00178"></a>00178 <span class="comment"> * \section new_model Adding a new Model</span>
<a name="l00179"></a>00179 <span class="comment"> * Please use the Unigram_Model implementation as an example to implement new models</span>
<a name="l00180"></a>00180 <span class="comment"> *</span>
<a name="l00181"></a>00181 <span class="comment"> * \section chkpt Checkpoints</span>
<a name="l00182"></a>00182 <span class="comment"> * The framework also provide checkpointing functionality for the multi-machine setup</span>
<a name="l00183"></a>00183 <span class="comment"> * in order to provide failure recovery. This is implemented by an external object</span>
<a name="l00184"></a>00184 <span class="comment"> * that knows how to do three things: a. Serialize metadata to disk b. load previously</span>
<a name="l00185"></a>00185 <span class="comment"> * serialized metadata on request c. Serialize the datastructures to disk</span>
<a name="l00186"></a>00186 <span class="comment"> *</span>
<a name="l00187"></a>00187 <span class="comment"> * An appropriate checkpointer is passed as an argument while creating an Execution_Strategy</span>
<a name="l00188"></a>00188 <span class="comment"> * The strategy uses checkpointers to checkpoint at regular intervals. At startup, it also</span>
<a name="l00189"></a>00189 <span class="comment"> * checks if any checkpoints are available and if so, it starts up from that checkpoint.</span>
<a name="l00190"></a>00190 <span class="comment"> *</span>
<a name="l00191"></a>00191 <span class="comment"> * Different checkpointers are needed for different setups. For ex., the framework uses</span>
<a name="l00192"></a>00192 <span class="comment"> * the Local Checkpointer when running in single machine mode which only involves writing</span>
<a name="l00193"></a>00193 <span class="comment"> * the iteration number as metadata. All other data needed for restart is already being</span>
<a name="l00194"></a>00194 <span class="comment"> * serialized. However, for the multi-machine setup, a different mechanism is needed and</span>
<a name="l00195"></a>00195 <span class="comment"> * a Hadoop Checkpointer is implemented.</span>
<a name="l00196"></a>00196 <span class="comment"> *</span>
<a name="l00197"></a>00197 <span class="comment"> * This is an ongoing effort and we will add more stuff both to the code and documentation.</span>
<a name="l00198"></a>00198 <span class="comment"> * We definitely need your help &amp; contribution in making this better.</span>
<a name="l00199"></a>00199 <span class="comment"> *</span>
<a name="l00200"></a>00200 <span class="comment"> * Here is an initial set of TODOs:</span>
<a name="l00201"></a>00201 <span class="comment"> *</span>
<a name="l00202"></a>00202 <span class="comment"> * \todo Add unit tests to make the code more robust</span>
<a name="l00203"></a>00203 <span class="comment"> * \todo Add more code documentation for the Unigram_Model components</span>
<a name="l00204"></a>00204 <span class="comment"> * \todo Implement fancier models in later versions</span>
<a name="l00205"></a>00205 <span class="comment"> * \todo Implement extensions to the LDA model in later versions</span>
<a name="l00206"></a>00206 <span class="comment"> *</span>
<a name="l00207"></a>00207 <span class="comment"> * These are in no particular order and we might re-prioritize later. Please mail me if</span>
<a name="l00208"></a>00208 <span class="comment"> * you are interested in contributing</span>
<a name="l00209"></a>00209 <span class="comment"> *</span>
<a name="l00210"></a>00210 <span class="comment"> * We shall use the git pull request (fork + pull model) for collaborative development.</span>
<a name="l00211"></a>00211 <span class="comment"> */</span>
</pre></div></div>
<hr class="footer"/><address style="text-align: right;"><small>Generated on Wed May 25 15:17:00 2011 for Y!LDA by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.3 </small></address>
</body>
</html>
